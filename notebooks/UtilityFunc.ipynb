{"cells":[{"cell_type":"code","source":["import pandas as pd\n","import json\n","from notebookutils import mssparkutils\n","from pyspark.sql import functions as F\n","from datetime import datetime\n","\n","def generateValidationHtml(result, max_unexpected=5):\n","    \"\"\"\n","    Generate an HTML report from a Great Expectations CheckpointResult object.\n","    \"\"\"\n","    # Access attributes directly\n","    run_id = getattr(result, \"run_id\", {})\n","\n","    # Grab runtime and nicely format it\n","    run_time_dt = getattr(run_id,\"run_time\")\n","    run_time = run_time_dt.strftime(\"%Y-%m-%d %H:%M:%S %Z\")\n","    \n","    # Extract first validation result\n","    run_results = getattr(result, \"run_results\", {})\n","    first_key = next(iter(run_results.keys()))\n","    validation_json = run_results[first_key]\n","\n","\n","    # Collect rows for HTML table\n","    rows = []\n","    for res in validation_json.get(\"results\", []):\n","        cfg = res.get(\"expectation_config\", {})\n","        res_result = res.get(\"result\", {})\n","\n","        rows.append({\n","            \"Title\": cfg.get(\"meta\", {}).get(\"title\", \"\"),\n","            \"Description\": cfg.get(\"meta\", {}).get(\"description\", \"\"),\n","            \"Column\": cfg.get(\"kwargs\", {}).get(\"column\", \"\"),\n","            \"Expectation\": cfg.get(\"type\", \"\"),\n","            \"Success\": res.get(\"success\", False),\n","            \"Unexpected Count\": res_result.get(\"unexpected_count\", 0),\n","            \"Unexpected %\": round(res_result.get(\"unexpected_percent\", 0), 2),\n","            \"Unexpected Values (sample)\": \", \".join(\n","                map(str, res_result.get(\"unexpected_list\", [])[:max_unexpected])\n","            )\n","        })\n","    \n","    \n","\n","    df = pd.DataFrame(rows)\n","\n","    html_output = getHTML(df, run_time)\n","\n","    return html_output"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":-1,"statement_ids":[],"state":"session_starting","livy_statement_state":null,"session_id":null,"normalized_state":"session_starting","queued_time":"2025-09-30T11:57:31.4084542Z","session_start_time":"2025-09-30T11:57:31.4099735Z","execution_start_time":null,"execution_finish_time":null,"parent_msg_id":"69822d01-dc06-4157-a012-3cc77eef15af"},"text/plain":"StatementMeta(, , -1, SessionStarting, , SessionStarting)"},"metadata":{}}],"execution_count":1,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"570fe4a5-a1fb-46cd-9c55-7e8ea546e65e"},{"cell_type":"code","source":["def getHTML(df, run_time, title=\"Validation Report\"):\n","\n","    failed_count = df.loc[df[\"Success\"] == False, \"Unexpected Count\"].sum()\n","\n","    styled_html = df.to_html(index=False, escape=False, border=0, classes=\"table table-bordered table-striped\")\n","\n","    # Build final HTML output\n","    html_output = f\"\"\"\n","    \n","    <html>\n","        <head>\n","            <style>\n","            body {{\n","                font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;\n","                margin: 5px;\n","                background-color: #f9fafb;\n","                color: #333;\n","            }}\n","            h2 {{\n","                text-align: left;\n","                color: #2c3e50;\n","            }}\n","            p {{\n","                text-align: left;\n","                font-size: 14px;\n","                color: #555;\n","                font-weight: bold;\n","            }}\n","            table {{\n","                margin: 20px auto;\n","                width: 100%;\n","                background: white;\n","                box-shadow: 0 2px 8px rgba(0,0,0,0.1);\n","                border-radius: 8px;\n","            }}\n","            thead {{\n","                background: #2c3e50;\n","                color: white;\n","                text-transform: uppercase;\n","                letter-spacing: 0.03em;\n","                font-size: 13px;\n","            }}\n","            th, td {{\n","                padding: 12px 15px;\n","                border-bottom: 1px solid #e0e0e0;\n","                text-align: left;\n","            }}\n","            tr:nth-child(even) {{\n","                background-color: #fafafa;\n","            }}\n","            .fail {{\n","                background-color: #fde2e2 !important;\n","                color: #b71c1c;\n","                font-weight: bold;\n","            }}\n","            .success {{\n","                background-color: #e6f4ea !important;\n","                color: #1b5e20;\n","                font-weight: bold;\n","            }}\n","            .alert {{\n","                color: red;\n","                font-weight: bold;\n","            }}\n","            </style>\n","        </head>\n","        <body>\n","            <h2>{title}</h2>\n","            <p>Run Time: {run_time}</p>\n","            <p class =\"alert\">{failed_count} record(s) dropped due to validation error. Please review.</p>\n","            {styled_html}\n","        </body>\n","    </html>\n","    \"\"\"\n","    return html_output\n"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"145affc8-70be-4f5d-b13e-89a6893ca8be"},{"cell_type":"code","source":["# Get cleaned data and failed records\n","def cleanData(df, checkpoint_result):\n","    run_results = getattr(checkpoint_result, \"run_results\", {})\n","    failed_queries = []\n","\n","    for _, validation in run_results.items():\n","        for res in validation.get(\"results\", []):\n","            if not res.get(\"success\", True):\n","                raw_query = res.get(\"result\", {}).get(\"unexpected_index_query\")\n","                if raw_query:\n","                    # Remove Python wrapper if present\n","                    if \"F.expr(\" in raw_query:\n","                        raw_query = raw_query.split(\"F.expr(\")[-1].rstrip(\")\").strip()\n","\n","                    # Ensure parentheses balance\n","                    open_parens = raw_query.count(\"(\")\n","                    close_parens = raw_query.count(\")\")\n","                    if open_parens > close_parens:\n","                        raw_query += \")\" * (open_parens - close_parens)\n","\n","                    failed_queries.append(f\"({raw_query})\")\n","\n","    if failed_queries:\n","        combined = \" OR \".join(failed_queries)\n","        print(\"Final combined SQL:\\n\", combined)  # debug\n","\n","        failed_df = df.filter(F.expr(combined))\n","        cleaned_df = df.exceptAll(failed_df)\n","        return cleaned_df, failed_df\n","\n","    return df, None\n"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"0d79ceec-8f90-4a00-9404-e06211ddda52"},{"cell_type":"code","source":["# Summarize report\n","def summarizeReport(result):\n","    html_report = generateValidationHtml(result)\n","    run_results = getattr(result, \"run_results\", {})\n","\n","    # take overall success (from first validation block, usually sufficient)\n","    first_key = next(iter(run_results.keys()))\n","    validation_json = run_results[first_key]\n","\n","    # overall success\n","    overall_success = validation_json.get(\"success\", False)\n","\n","    # count failed rows across all expectations\n","    total_failed = sum(\n","        res.get(\"result\", {}).get(\"unexpected_count\", 0)\n","        for res in validation_json.get(\"results\", [])\n","    )\n","\n","    # create a details/title string\n","    summary = f\"Validation Failure - {total_failed} row(s) failed checks\"\n","\n","    output = {\n","        \"success\": overall_success,\n","        \"summary\": summary,   # ðŸ”¹ new field for your title\n","        \"details\": html_report\n","    }\n","    return json.dumps(output, indent=2)\n"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"9a162842-3c12-4b04-803e-e60fdcbbdfb5"},{"cell_type":"code","source":["import smtplib\n","from email.mime.text import MIMEText\n","from email.mime.multipart import MIMEMultipart\n","import json\n","from notebookutils import mssparkutils\n","\n","# Send Validation alert\n","def sendNotification(report):\n","\n","    workspace = \"Logistics\"\n","    lakehouse = \"Shipments_LH\"\n","\n","    # Path to email/app credentials\n","    path = f\"abfss://{workspace}@onelake.dfs.fabric.microsoft.com/{lakehouse}.Lakehouse/Files/notification/notify.json\"\n","\n","    json_text = mssparkutils.fs.head(path)\n","\n","    cred = json.loads(json_text)\n","\n","    # SMTP settings\n","    smtp_server = \"smtp.gmail.com\"\n","    smtp_port = 587\n","    username = cred[\"username\"]\n","    password = cred[\"password\"]  # or app password if MFA\n","\n","    # Create the email\n","    msg = MIMEMultipart(\"alternative\")\n","    msg[\"Subject\"] = report[\"summary\"] # Grab summary from  report json\n","  \n","    msg[\"From\"] = username\n","    msg[\"To\"] = cred[\"target_email\"]\n","\n","    html_part = MIMEText(report[\"details\"], \"html\") # Grab  html report and table \n","    msg.attach(html_part)\n","\n","    with smtplib.SMTP(smtp_server, smtp_port) as server:             \n","        server.starttls()            \n","        server.login(username, password)\n","        server.send_message(msg)\n","\n","# Poke around built docs    \n","# !cp gx/uncommitted/data_docs/local_site/index.html /lakehouse/default/Files \n"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"cd1ea31c-1c28-49a3-9d70-f2fcc681e3ad"},{"cell_type":"code","source":["# Write file to Lakehouse\n","def writetToLH(data, path):\n","    mssparkutils.fs.put(path, data, overwrite=True)\n","    print(f\"Saved HTML report to Lakehouse at: {path}\")"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"8b707039-add3-48f4-a7d1-fa35768771e7"}],"metadata":{"kernel_info":{"name":"synapse_pyspark"},"kernelspec":{"name":"synapse_pyspark","display_name":"synapse_pyspark"},"language_info":{"name":"python"},"microsoft":{"language":"python","language_group":"synapse_pyspark","ms_spell_check":{"ms_spell_check_language":"en"}},"nteract":{"version":"nteract-front-end@1.0.0"},"spark_compute":{"compute_id":"/trident/default","session_options":{"conf":{"spark.synapse.nbs.session.timeout":"1200000"}}},"dependencies":{"environment":{"environmentId":"40c4fb71-936a-4a96-8eb7-9058cfc20253","workspaceId":"eddafb60-2442-43df-958c-20f60a7117a5"}}},"nbformat":4,"nbformat_minor":5}